{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA LAKES",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarPortales/BootCamp/blob/master/DATA_LAKES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnmqUc6QywSX",
        "colab_type": "text"
      },
      "source": [
        "# DATA LAKES\n",
        "\n",
        "![texto alternativo](https://knowledgent.com/wp-content/uploads/2014/09/The-Supervised-Data-Lake_GraphicOnly.png)\n",
        "\n",
        "## Características\n",
        "\n",
        "* Uso de múltiples herramientas y productos\n",
        "* Especificación del dominio\n",
        "* Gestión automatizada de metadatos.\n",
        "* Flujos de trabajo de ingestión configurables.\n",
        "\n",
        "## Metadatos???\n",
        "\n",
        "- Datos acerca de los datos (cantidad, dominio, naturaleza, extractos, etc)\n",
        "- Governance\n",
        "- La preparación y limpieza de datos requieren un conocimiento sólido de qué conjunto de datos está trabajando. \n",
        "- Diferentes conjuntos requieren diferentes tipos de preparación, en función de lo que has aprendido sobre ellos históricamente.\n",
        "- Limpiar datos y prevenir errores.\n",
        "- Las licencias pueden requerir restricciones de acceso y otro tratamiento especial de algunas fuentes de datos. (GDPR, etc)\n",
        "\n",
        "## Diseño de un Data lake\n",
        "\n",
        "### Definición la estrategia del DAaaS\n",
        "\n",
        "Definir el catálogo de servicios que proporcionará la plataforma DAaaS, que incluye incorporación de datos, limpieza de datos, transformación de datos, datapedias, bibliotecas de herramientas analíticas y otros.\n",
        "\n",
        "\n",
        "### Arquitectura DAaaS\n",
        "\n",
        "Definir la selección de componentes, la definición de procesos de ingeniería y el diseño de interfaces de usuario.\n",
        "Diseño y ejecución de Proofs-of-Concept (PoC) para demostrar la viabilidad del enfoque DAaaS.\n",
        "\n",
        "\n",
        "### DAaaS Operating Model Design and Rollout\n",
        "\n",
        "Personalizar los modelos operativos DAaaS para cumplir con los procesos, la estructura organizacional, las reglas y el gobierno de los clientes individuales. \n",
        "Realizar seguimiento de consumo y mecanismos de informe.\n",
        "\n",
        "\n",
        "### Desarrollo de la plataforma DAaaS.\n",
        "\n",
        "Construcción iterativa de todas las capacidades de la plataforma, incluido el diseño, desarrollo e integración, **pruebas**, carga de datos, metadatos y población de catálogos, y despliegue.\n",
        "\n",
        "\n",
        "## Retos de un Data Lake\n",
        "\n",
        "### Timeliness\n",
        "El acceso a datos debe ser  rapido\n",
        "los usuarios gastaran tiempo en sacar datos de sql db, guardarla y evaluarla por su cuenta: NO!\n",
        "\n",
        "\n",
        "### Flexibility\n",
        "\n",
        "acceso a datos con herramientas propias de cada usuario\n",
        "el usuario debe ser capaz de analizar datos de cualquier formato\n",
        "\n",
        "\n",
        "### Quality\n",
        "\n",
        "el usuario no debe dudar de los datos\n",
        "trust is everything, quality is everything\n",
        "si no confian, haran circumvent <- FATAL!\n",
        "\n",
        "\n",
        "### Findability. \n",
        "\n",
        "Al haber muchos datos necesitas que los usuarios puedan encontrar datos rapido\n",
        "\n",
        "![texto alternativo](https://i.imgur.com/GrVszRZ.png)\n",
        "\n",
        "## Mas lectura\n",
        "\n",
        "- https://tdwi.org/articles/2017/10/16/arch-all-data-lake-manifesto-10-best-practices.aspx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn4fceNo3SIW",
        "colab_type": "text"
      },
      "source": [
        "# VOLVAMOS A HADOOP!!!\n",
        "\n",
        "Como habiamos hablado, hadoop son 4 elementos principales:\n",
        "\n",
        "- HDFS\n",
        "- MapReduce\n",
        "- YARN\n",
        "- Common\n",
        "\n",
        "## Venga, vamos con YARN\n",
        "\n",
        "Que podemos hacer con YARN?\n",
        "\n",
        "1.    Primero siempre entramos en el directorio de instalacion de hadoop de la VM:\n",
        "```\n",
        "cd $HADOOP_PREFIX\n",
        "```\n",
        "2.   Luego podemos ejecutar jobs de mapreduce con `bin/yarn` o `bin/hadoop` :\n",
        "\n",
        "```\n",
        "bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 10 10\n",
        "\n",
        "bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 10 10\n",
        "```\n",
        "\n",
        "La diferencia radica en como *YARN* va a manejar los recursos internamente y podeis leer al respecto aqui: \n",
        "https://stackoverflow.com/questions/22769129/differences-between-hadoop-jar-and-yarn-jar\n",
        "\n",
        "\n",
        "Para ver lista de jobs en ejecucion\n",
        "\n",
        "```\n",
        "./bin/hadoop job -list\n",
        "```\n",
        "\n",
        "Para matar un job:\n",
        "\n",
        "```\n",
        "./bin/yarn application -kill XXXAPPIDXXX\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### Nueva URL para jugar!\n",
        "\n",
        "http://127.0.0.1:8088/cluster\n",
        "\n",
        "Podemos:\n",
        "- Ver historial\n",
        "- Matar applications\n",
        "- Ver detalles de aplicaciones\n",
        "\n",
        "### Logs\n",
        "\n",
        "Todos los logs: \n",
        "- http://127.0.0.1:8088/logs/\n",
        "- http://127.0.0.1:8088/logs/userlogs/\n",
        "\n",
        "### Scheduling\n",
        "\n",
        "Se utilizan colas, hay una cola principal llamada root, el resto se pueden definir de la siguiente forma:\n",
        "\n",
        "![job scheduling](http://blog.cloudera.com/wp-content/uploads/2015/12/untangling-yarn-3-f1.png)\n",
        "\n",
        "```\n",
        "./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 2 3 &\n",
        "./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 2 3 &\n",
        "./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 2 3 &\n",
        "```\n",
        "\n",
        "\n",
        "Otra URL! http://127.0.0.1:8088/cluster/scheduler\n",
        "\n",
        "***NOTA***: La personalización del Fair Job Scheduler generalmente implica la alteración de dos archivos. \n",
        "\n",
        "\n",
        "En primer lugar, las opciones de todo el planificador se pueden establecer agregando propiedades de configuración en el archivo yarn-site.xml en su directorio de configuración existente. \n",
        "\n",
        "1.    Primero entramos en el directorio donde se encuentran los ficheros de configuracion:\n",
        "```\n",
        "cd /usr/local/hadoop/etc/hadoop\n",
        "```\n",
        "2.    Con esto podemos ver los contenidos del yarn-site.xml (El fichero de configuracion principal de YARN)\n",
        "```\n",
        "cat yarn-site.xml\n",
        "```\n",
        "3.   Para editarlo debemos utilizar vi (https://txikano.files.wordpress.com/2006/12/manual_rapido_vi.pdf):\n",
        "```\n",
        "vi yarn-site.xml\n",
        "```\n",
        "\n",
        "Copiar esto dentro:\n",
        "\n",
        "```\n",
        "<property>\n",
        "  <name>yarn.resourcemanager.scheduler.class</name>\n",
        "  <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>\n",
        "</property>\n",
        "<property>\n",
        "  <name>yarn.scheduler.fair.allocation.file</name>\n",
        "  <value>/usr/local/hadoop/etc/hadoop/fair-scheduler.xml</value>\n",
        "</property>\n",
        "```\n",
        "\n",
        "Visitar http://127.0.0.1:8088/conf y buscar scheduler.\n",
        "\n",
        "Segundo, en la mayoría de los casos, los usuarios querrán crear un archivo de asignación que enumere qué colas existen y sus respectivos pesos y capacidades. El archivo de asignación se vuelve a cargar cada 10 segundos, lo que permite realizar cambios sobre la marcha.\n",
        "\n",
        "```\n",
        "vi fair-scheduler.xml\n",
        "```\n",
        "\n",
        "Copiar esto dentro: \n",
        "NOTA: Esto se puede configurar mucho mas profudamente. Poner colas padre, etc.\n",
        "\n",
        "```\n",
        "<?xml version=\"1.0\"?>\n",
        "<allocations>\n",
        "  <queue name=\"test_queue_80\">\n",
        "    <weight>80.0</weight>\n",
        "  </queue>\n",
        "  <queue name=\"test_queue_20\">\n",
        "  <weight>20.0</weight>\n",
        "  </queue>\n",
        "</allocations>\n",
        "```\n",
        "\n",
        "\n",
        "Para retomar estos cambios hay que reiniciar YARN en todos los nodos:\n",
        "\n",
        "```\n",
        "cd $HADOOP_PREFIX\n",
        "./sbin/stop-yarn.sh\n",
        "./sbin/start-yarn.sh\n",
        "```\n",
        "\n",
        "Visitar http://127.0.0.1:8088/conf\n",
        "\n",
        "Documentacion de scheduler: https://hadoop.apache.org/docs/r2.7.4/hadoop-yarn/hadoop-yarn-site/FairScheduler.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf2cpQh-1hY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P8iOwlN_zt3",
        "colab_type": "text"
      },
      "source": [
        "## Volvamos a la teoria un momento\n",
        "\n",
        "YARN al final no es mas que una capa de control sobre las aplicaciones o comandos que corren sobre hadoop.\n",
        "\n",
        "Es una capa muy cercana al HDFS y de bastante bajo nivel, hecha en JAVA.\n",
        "\n",
        "![yarn arch](https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/images/hddg_0401.png)\n",
        "\n",
        "### Que sucede cuando YARN supervisa una ejecucion?\n",
        "\n",
        "![yarn process](https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/images/hddg_0402.png)\n",
        "\n",
        "### Mas lectura\n",
        "- https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/ch04.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnIEmdkV1LdU",
        "colab_type": "text"
      },
      "source": [
        "## De vuelta a la instancia\n",
        "\n",
        "### Como enviar un job a una cola especifica?\n",
        "\n",
        "```\n",
        "./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi -D mapred.job.queue.name=root.test_queue_20 -D mapred.job.name=test20 100 200 &\n",
        "./bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi -D mapred.job.queue.name=root.test_queue_80 -D mapred.job.name=test80 100 120 &\n",
        "\n",
        "bin/mapred job -logs JOBID\n",
        "\n",
        "```\n",
        "\n",
        "Ahora visitemos:\n",
        "http://127.0.0.1:8088/cluster/scheduler\n",
        "\n",
        "Puede ser tan complejo como:\n",
        "\n",
        "![complex yarn](http://blog.cloudera.com/wp-content/uploads/2016/01/untangling-yarn-3-f2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6wHF9Vf49Mg",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Con la arquitectura provista por HDFS + YARN + MAP REDUCE podemos obtener un modelo de arquitectura big data inicial, faltan muchas herramientas y conceptos como:\n",
        "\n",
        "- Seguridad\n",
        "- Gestion de Usuarios\n",
        "- Deployment\n",
        "- Testing\n",
        "- CI/CD\n",
        "- Cluster design\n",
        "- SEGURIDAD!\n",
        "- Cloud vs in premise\n",
        "- Flujo de trabajo\n",
        "\n",
        "\n",
        "#### Un entorno de hadoop + yarn apunta hacia este diseño:\n",
        "\n",
        "![yarn total](https://2xbbhjxc6wk3v21p62t8n4d4-wpengine.netdna-ssl.com/wp-content/uploads/2014/07/data.png)\n",
        "\n",
        "\n",
        "#### Y aun asi!\n",
        "\n",
        "Encima de esto pueden ir mas cosas, o al lado, etc (Spark, KAFKA, etc)... Pero ya veremos mas cosas.\n",
        "\n",
        "\n",
        "## BONUS COMIC:\n",
        "\n",
        "![texto alternativo](https://marketoonist.com/wp-content/uploads/2014/01/140113.bigdata.jpg)\n",
        "\n"
      ]
    }
  ]
}